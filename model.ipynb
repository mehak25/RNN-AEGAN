{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, IterableDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda(tensor):\n",
    "    if T.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' C-RNN-GAN generator\n",
    "    '''\n",
    "    def __init__(self, num_feats, hidden_units, drop_prob=0.6, use_cuda=True):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hidden_dim = hidden_units\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_feats = num_feats\n",
    "\n",
    "        #self.fc_layer1 = nn.Linear(in_features=num_feats, out_features=hidden_units)\n",
    "        self.lstm1 = nn.LSTM(num_feats, 600, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(600, 500,1, batch_first=True)\n",
    "        #self.dropout = nn.Dropout(p=drop_prob, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(500, 400,2, batch_first=True)\n",
    "        \n",
    "\n",
    "    def forward(self, z):\n",
    "        ''' Forward prop\n",
    "        '''\n",
    "        if self.use_cuda:\n",
    "            z = z.cuda()\n",
    "\n",
    "        h, (h_n, c_n) = self.lstm1(z)\n",
    "        h, (h_n, c_n) = self.lstm2(h)\n",
    "        h, (h_n, c_n) = self.lstm3(h)\n",
    "        return h, (h_n, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    ''' C-RNN-GAN generator\n",
    "    '''\n",
    "    def __init__(self, num_feats, hidden_units, drop_prob=0.6, use_cuda=True):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hidden_dim = hidden_units\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_feats = num_feats\n",
    "\n",
    "        self.lstm1 = nn.LSTM(400, 500, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(500, 1,2, batch_first=True)\n",
    "        self.fc_layer1 = nn.Linear(in_features=1, out_features=1)\n",
    "        #self.fc_layer2 = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, z,states):\n",
    "        ''' Forward prop\n",
    "        '''\n",
    "        (h0,c0)=states\n",
    "        if self.use_cuda:\n",
    "            z = z.cuda()\n",
    "            h0=h0.cuda()\n",
    "            c0=c0.cuda()\n",
    "        batch_size, seq_len, num_feats = z.shape\n",
    "        h, (h_n, c_n) = self.lstm1(z)\n",
    "        h, (h_n, c_n) = self.lstm2(h)\n",
    "        fc_output=self.fc_layer1(h)\n",
    "        #fc_output=self.fc_layer2(fc_output)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    ''' C-RNN-GAN discrminator\n",
    "    '''\n",
    "    def __init__(self, num_feats, hidden_units, use_cuda=False):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # params\n",
    "        self.hidden_dim = hidden_units\n",
    "        self.num_layers = 1\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=10,\n",
    "                            num_layers=self.num_layers, batch_first=True,bidirectional=True)\n",
    "        self.fc_layer1 = nn.Linear(in_features=(2*10), out_features=10)\n",
    "        self.fc_layer2 = nn.Linear(in_features=10, out_features=5)\n",
    "        self.fc_layer3 = nn.Linear(in_features=5, out_features=1)\n",
    "\n",
    "    def forward(self, note_seq,flag):\n",
    "        ''' Forward prop\n",
    "        '''\n",
    "        #print(\"FORWARD\")\n",
    "        if self.use_cuda:\n",
    "            note_seq = note_seq.cuda()\n",
    "\n",
    "        lstm_out, state = self.lstm(note_seq)\n",
    "        (h_n,c_n)=state\n",
    "        h_n = T.cat((h_n[0],h_n[1]),dim=1)\n",
    "        out = self.fc_layer1(h_n)\n",
    "        out = self.fc_layer2(out)\n",
    "        out = self.fc_layer3(out)\n",
    "        num_dims = len(out.shape)\n",
    "        reduction_dims = tuple(range(1, num_dims))\n",
    "        out = T.mean(out, dim=reduction_dims)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path, chunksize,length,seq_len):\n",
    "        self.path = path\n",
    "        self.chunksize = chunksize\n",
    "        self.len = int(length)#number of times total getitem is called\n",
    "        self.seq_len=seq_len\n",
    "        self.reader=pd.read_csv(\n",
    "                self.path,header=0,\n",
    "                chunksize=self.chunksize)#,names=['data']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.reader.get_chunk(self.chunksize)\n",
    "        #sex=pd.read_csv('C:\\\\Users/mehak/Desktop/demo.csv',header=0)\n",
    "        #sex=sex[['person_id','Sex']]\n",
    "        #data = pd.merge(data, sex, how='left', on=['person_id'])\n",
    "        del data['person_id']\n",
    "           \n",
    "        data=data.replace(np.nan,0)\n",
    "        \n",
    "        data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "        data=data.view(int(data.shape[0]/self.seq_len), self.seq_len, data.shape[1])\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, optimizer, save_path):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer, save_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer, save_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, optimizer, save_path):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        T.save({\n",
    "            \"E_model\": model['e'].state_dict(),\n",
    "            \"G_model\": model['g'].state_dict(),\n",
    "            \"D_model\": model['d'].state_dict(),\n",
    "            'E_trainer': optimizer['e'].state_dict(),\n",
    "            'G_trainer': optimizer['g'].state_dict(),\n",
    "            'D_trainer': optimizer['d'].state_dict()\n",
    "        }, save_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
